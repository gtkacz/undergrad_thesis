{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p align=\"center\">\n",
    "        <img src=\"https://logodownload.org/wp-content/uploads/2017/09/mackenzie-logo-3.png\" style=\"height: 7ch;\"><br>\n",
    "        <h1 align=\"center\">Computer Systems Undergradute Thesis</h1>\n",
    "        <h2 align=\"center\">Quantitative Analysis of the Impact of Image Pre-Processing on the Accuracy of Computer Vision Models Trained to Identify Dermatological Skin Diseases</a>\n",
    "        <h4 align=\"center\">Gabriel Mitelman Tkacz</a>\n",
    "        </h4>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import tomllib\n",
    "from functools import partial\n",
    "from itertools import permutations\n",
    "from pprint import pprint\n",
    "\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "from matplotlib.font_manager import FontProperties, fontManager\n",
    "from PIL import Image\n",
    "from pynimbar import loading_animation\n",
    "\n",
    "from util import (\n",
    "\tColorSpaceTransform,\n",
    "\tDenoiseTransform,\n",
    "\tEqualizationTransform,\n",
    "\tNormalizeTransform,\n",
    "\tevaluate_model,\n",
    "\tget_model_data,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PREPROCESS': {'colorspace': {'high_con': {'source_space': 'RGB',\n",
      "                                            'target_space': 'LAB'},\n",
      "                               'source_space': 'RGB',\n",
      "                               'target_space': 'HSV'},\n",
      "                'denoise': {'high_con': {'search_window_size': 24,\n",
      "                                         'template_window_size': 6},\n",
      "                            'search_window_size': 19,\n",
      "                            'template_window_size': 5},\n",
      "                'normalize': {'high_con': {'mean': 0.3, 'std': 0.75},\n",
      "                              'mean': 0.4,\n",
      "                              'std': 0.2}},\n",
      " 'TRAINING': {'batch_size': 128,\n",
      "              'diseased_skin_path': './dataset/diseased/',\n",
      "              'healthy_skin_path': './dataset/healthy/',\n",
      "              'learning_rate': 0.0001,\n",
      "              'num_epochs': 3,\n",
      "              'num_workers': 12,\n",
      "              'pin_memory': True,\n",
      "              'precision_threshold': 0.8,\n",
      "              'resize_dim': 128,\n",
      "              'shuffle': True,\n",
      "              'training_dataset_ratio': 0.8}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"parameters.toml\") as f:\n",
    "\tparameters = tomllib.loads(f.read())\n",
    "\n",
    "loading_handler = partial(loading_animation, break_on_error=True, verbose_errors=True, time_it_live=True)\n",
    "\n",
    "alpha = chr(0x03B1)\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ColorSpaceTransform(), DenoiseTransform(), EqualizationTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>)\n",
      "(ColorSpaceTransform(), DenoiseTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, EqualizationTransform())\n",
      "(ColorSpaceTransform(), EqualizationTransform(), DenoiseTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>)\n",
      "(ColorSpaceTransform(), EqualizationTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, DenoiseTransform())\n",
      "(ColorSpaceTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, DenoiseTransform(), EqualizationTransform())\n",
      "(ColorSpaceTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, EqualizationTransform(), DenoiseTransform())\n",
      "(DenoiseTransform(), ColorSpaceTransform(), EqualizationTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>)\n",
      "(DenoiseTransform(), ColorSpaceTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, EqualizationTransform())\n",
      "(DenoiseTransform(), EqualizationTransform(), ColorSpaceTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>)\n",
      "(DenoiseTransform(), EqualizationTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, ColorSpaceTransform())\n",
      "(DenoiseTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, ColorSpaceTransform(), EqualizationTransform())\n",
      "(DenoiseTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, EqualizationTransform(), ColorSpaceTransform())\n",
      "(EqualizationTransform(), ColorSpaceTransform(), DenoiseTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>)\n",
      "(EqualizationTransform(), ColorSpaceTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, DenoiseTransform())\n",
      "(EqualizationTransform(), DenoiseTransform(), ColorSpaceTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>)\n",
      "(EqualizationTransform(), DenoiseTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, ColorSpaceTransform())\n",
      "(EqualizationTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, ColorSpaceTransform(), DenoiseTransform())\n",
      "(EqualizationTransform(), <util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, DenoiseTransform(), ColorSpaceTransform())\n",
      "(<util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, ColorSpaceTransform(), DenoiseTransform(), EqualizationTransform())\n",
      "(<util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, ColorSpaceTransform(), EqualizationTransform(), DenoiseTransform())\n",
      "(<util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, DenoiseTransform(), ColorSpaceTransform(), EqualizationTransform())\n",
      "(<util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, DenoiseTransform(), EqualizationTransform(), ColorSpaceTransform())\n",
      "(<util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, EqualizationTransform(), ColorSpaceTransform(), DenoiseTransform())\n",
      "(<util.preprocessing.NormalizeTransform object at 0x7bf653b36930>, EqualizationTransform(), DenoiseTransform(), ColorSpaceTransform())\n"
     ]
    }
   ],
   "source": [
    "preprocesses = (\n",
    "\tColorSpaceTransform(**parameters[\"PREPROCESS\"][\"colorspace\"][\"high_con\"]),\n",
    "\tDenoiseTransform(**parameters[\"PREPROCESS\"][\"denoise\"][\"high_con\"]),\n",
    "\tEqualizationTransform(),\n",
    "\tNormalizeTransform(**parameters[\"PREPROCESS\"][\"normalize\"][\"high_con\"]),\n",
    ")\n",
    "\n",
    "preprocess_combinations = {i: permutations(preprocesses, i) for i in range(1, len(preprocesses) + 1)}\n",
    "\n",
    "preprocess_labels = {s.__class__.__name__: re.sub(r\"[^A-Z]\", \"\", s.__class__.__name__)[:-1] for s in preprocesses}\n",
    "\n",
    "for i in preprocess_combinations[4]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ratio: 80.0%\n",
      "Testing ratio: 10.0%\n",
      "Validation ratio: 10.0%\n",
      "\n",
      "Seed: 47\n"
     ]
    }
   ],
   "source": [
    "training_ratio = parameters[\"TRAINING\"][\"training_dataset_ratio\"]\n",
    "testing_ratio = validation_ratio = round(1 - training_ratio, 1) / 2\n",
    "\n",
    "print(f\"Training ratio: {training_ratio * 100}%\")\n",
    "print(f\"Testing ratio: {testing_ratio * 100}%\")\n",
    "print(f\"Validation ratio: {validation_ratio * 100}%\")\n",
    "\n",
    "seed = 47\n",
    "print(f\"\\nSeed: {seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_path = \"./fonts/Times-New-Roman.otf\"\n",
    "fontManager.addfont(font_path)\n",
    "\n",
    "prop = FontProperties(fname=font_path)\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_theme(\n",
    "\tfont=prop.get_name(),\n",
    "\tstyle=\"whitegrid\",\n",
    "\tpalette=\"deep\",\n",
    "\trc={\"font.size\": 12, \"axes.titlesize\": 20, \"axes.labelsize\": 18, \"xtick.labelsize\": 16, \"ytick.labelsize\": 16},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"./dataset/diseased/ISIC_0024319.jpg\"\n",
    "N_COLS = 3\n",
    "\n",
    "base_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "base_tensor = TF.to_tensor(base_pil)\n",
    "\n",
    "all_perms = [()]\n",
    "for comb_iter in preprocess_combinations.values():\n",
    "\tall_perms.extend(list(comb_iter))\n",
    "\n",
    "images, captions = [], []\n",
    "for perm in all_perms:\n",
    "\timg_t = base_tensor\n",
    "\tfor proc in perm:\n",
    "\t\timg_t = proc(img_t)\n",
    "\n",
    "\timages.append(TF.to_pil_image(img_t))\n",
    "\n",
    "\tif perm:\n",
    "\t\tlabels = [preprocess_labels[p.__class__.__name__] for p in perm]\n",
    "\t\tcaptions.append(\" → \".join(labels))\n",
    "\telse:\n",
    "\t\tcaptions.append(\"Original\")\n",
    "\n",
    "n_images = len(images)\n",
    "n_rows = math.ceil(n_images / N_COLS)\n",
    "fig, axes = plt.subplots(n_rows, N_COLS, figsize=(4 * N_COLS, 4 * n_rows))\n",
    "fig.patch.set_alpha(0)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img, title in zip(axes, images, captions, strict=False):\n",
    "\tax.set_title(\"\")\n",
    "\tax.imshow(img)\n",
    "\tax.axis(\"off\")\n",
    "\tax.text(\n",
    "\t\t0.5,\n",
    "\t\t-0.1,\n",
    "\t\ttitle,\n",
    "\t\tsize=25,\n",
    "\t\tha=\"center\",\n",
    "\t\ttransform=ax.transAxes,\n",
    "\t)\n",
    "\n",
    "\n",
    "for ax in axes[n_images:]:\n",
    "\tax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"preprocesses.png\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 0 Model: Images with no pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "\tbase_train_loader,\n",
    "\tbase_test_loader,\n",
    "\tbase_validation_loader,\n",
    ") = get_model_data(\n",
    "\ttraining_ratio=training_ratio,\n",
    "\ttesting_ratio=testing_ratio,\n",
    "\tvalidation_ratio=validation_ratio,\n",
    "\tseed=seed,\n",
    ")\n",
    "\n",
    "base_precision, base_confusion_matrix, base_training_time = evaluate_model(\n",
    "\tdevice, base_train_loader, base_test_loader, base_validation_loader,\n",
    ")\n",
    "\n",
    "print(f\"Base precision: {base_precision * 100:.1f}%\")\n",
    "\n",
    "if base_precision < parameters[\"TRAINING\"][\"precision_threshold\"]:\n",
    "\traise ValueError(\"The base model did not meet the precision threshold.\")\n",
    "\n",
    "base_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 1 Models: Images with only one pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1.1 Models: Normalizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "\tnormalize_train_loader,\n",
    "\tnormalize_test_loader,\n",
    "\tnormalize_validation_loader,\n",
    ") = get_model_data(\n",
    "\t[NormalizeTransform(**parameters[\"PREPROCESS\"][\"normalize\"][\"high_con\"])],\n",
    "\ttraining_ratio=training_ratio,\n",
    "\ttesting_ratio=testing_ratio,\n",
    "\tvalidation_ratio=validation_ratio,\n",
    "\tseed=seed,\n",
    ")\n",
    "\n",
    "normalize_precision, normalize_confusion_matrix, normalize_training_time = evaluate_model(\n",
    "\tdevice, normalize_train_loader, normalize_test_loader, normalize_validation_loader,\n",
    ")\n",
    "\n",
    "normalize_precision_diff = normalize_precision - base_precision\n",
    "\n",
    "print(f\"\\n\\nNormalized precision: {normalize_precision * 100:.1f}%\")\n",
    "print(\n",
    "\tf\"That is an {'upgrade' if normalize_precision_diff > 0 else 'downgrade'} of {normalize_precision_diff * 100:.1f}%.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./params/normalize_high_con.json\")\n",
    "\n",
    "df[\"precision\"] = df[\"precision\"].apply(lambda x: x[0])\n",
    "\n",
    "df[\"precision\"] = df[\"precision\"] - base_precision\n",
    "\n",
    "pivot_table = df.pivot(index=\"std\", columns=\"mean\", values=\"precision\")\n",
    "\n",
    "pivot_table = pivot_table.sort_index().sort_index(axis=1).iloc[::-1]\n",
    "\n",
    "pivot_table_pct = pivot_table * 100\n",
    "\n",
    "vabs = max(abs(pivot_table_pct.min().min()), abs(pivot_table_pct.max().max()))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "\tpivot_table_pct,\n",
    "\tannot=True,\n",
    "\tfmt=\".1f\",\n",
    "\tcmap=\"RdYlGn\",\n",
    "\tcbar_kws={\"label\": alpha, \"format\": \"%.0f%%\"},\n",
    "\tvmin=-vabs,\n",
    "\tvmax=vabs,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "plt.gca().set_xticklabels([f\"{x:.1f}\" for x in pivot_table_pct.columns])\n",
    "plt.gca().set_yticklabels([f\"{y:.1f}\" for y in pivot_table_pct.index])\n",
    "\n",
    "plt.title(\"Correlation between Normalization Parameters and Model Precision\")\n",
    "plt.xlabel(\"Mean\")\n",
    "plt.ylabel(\"Standard Deviation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1.2 Models: Denoising the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "\tdenoise_train_loader,\n",
    "\tdenoise_test_loader,\n",
    "\tdenoise_validation_loader,\n",
    ") = get_model_data(\n",
    "\t[DenoiseTransform(**parameters[\"PREPROCESS\"][\"denoise\"][\"high_con\"])],\n",
    "\ttraining_ratio=training_ratio,\n",
    "\ttesting_ratio=testing_ratio,\n",
    "\tvalidation_ratio=validation_ratio,\n",
    "\tseed=seed,\n",
    ")\n",
    "\n",
    "denoise_precision, denoise_confusion_matrix, denoise_training_time = evaluate_model(\n",
    "\tdevice, denoise_train_loader, denoise_test_loader, denoise_validation_loader,\n",
    ")\n",
    "\n",
    "denoise_precision_diff = denoise_precision - base_precision\n",
    "\n",
    "print(f\"\\n\\nDenoised precision: {denoise_precision * 100:.1f}%\")\n",
    "print(f\"That is an {'upgrade' if denoise_precision_diff > 0 else 'downgrade'} of {denoise_precision_diff * 100:.1f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./params/denoise_high_con.json\")\n",
    "\n",
    "df[\"precision\"] = df[\"precision\"].apply(lambda x: x[0])\n",
    "\n",
    "df[\"precision\"] = df[\"precision\"] - base_precision\n",
    "\n",
    "pivot_table = df.pivot(index=\"search_window_size\", columns=\"template_window_size\", values=\"precision\")\n",
    "\n",
    "pivot_table = pivot_table.sort_index().sort_index(axis=1).iloc[::-1]\n",
    "\n",
    "pivot_table_pct = pivot_table * 100\n",
    "\n",
    "vabs = max(abs(pivot_table_pct.min().min()), abs(pivot_table_pct.max().max()))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "\tpivot_table_pct,\n",
    "\tannot=True,\n",
    "\tfmt=\".1f\",\n",
    "\tcmap=\"RdYlGn\",\n",
    "\tcbar_kws={\"label\": alpha, \"format\": \"%.0f%%\"},\n",
    "\tvmin=-vabs,\n",
    "\tvmax=vabs,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "plt.gca().set_xticklabels([f\"{x:.0f}\" for x in pivot_table_pct.columns])\n",
    "plt.gca().set_yticklabels([f\"{y:.0f}\" for y in pivot_table_pct.index])\n",
    "\n",
    "plt.title(\"Correlation between Denoising Parameters and Model Precision\")\n",
    "plt.xlabel(\"Template Window Size\")\n",
    "plt.ylabel(\"Search Window Size\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1.3 Models: Equalizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "\tequalized_train_loader,\n",
    "\tequalized_test_loader,\n",
    "\tequalized_validation_loader,\n",
    ") = get_model_data(\n",
    "\t[EqualizationTransform()],\n",
    "\ttraining_ratio=training_ratio,\n",
    "\ttesting_ratio=testing_ratio,\n",
    "\tvalidation_ratio=validation_ratio,\n",
    "\tseed=seed,\n",
    ")\n",
    "\n",
    "equalized_precision, equalized_confusion_matrix, equalized_training_time = evaluate_model(\n",
    "\tdevice, equalized_train_loader, equalized_test_loader, equalized_validation_loader,\n",
    ")\n",
    "\n",
    "equalized_precision_diff = equalized_precision - base_precision\n",
    "\n",
    "print(f\"\\n\\nEqualized precision: {equalized_precision * 100:.1f}%\")\n",
    "print(\n",
    "\tf\"That is an {'upgrade' if equalized_precision_diff > 0 else 'downgrade'} of {equalized_precision_diff * 100:.1f}%.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1.4 Models: Changing the colorspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "\tcolorspace_train_loader,\n",
    "\tcolorspace_test_loader,\n",
    "\tcolorspace_validation_loader,\n",
    ") = get_model_data(\n",
    "\t[ColorSpaceTransform(**parameters[\"PREPROCESS\"][\"colorspace\"][\"high_con\"])],\n",
    "\ttraining_ratio=training_ratio,\n",
    "\ttesting_ratio=testing_ratio,\n",
    "\tvalidation_ratio=validation_ratio,\n",
    "\tseed=seed,\n",
    ")\n",
    "\n",
    "colorspace_precision, colorspace_confusion_matrix, colorspace_training_time = evaluate_model(\n",
    "\tdevice, colorspace_train_loader, colorspace_test_loader, colorspace_validation_loader,\n",
    ")\n",
    "\n",
    "colorspace_precision_diff = colorspace_precision - base_precision\n",
    "\n",
    "print(f\"\\n\\nColorspaced precision: {colorspace_precision * 100:.1f}%\")\n",
    "print(\n",
    "\tf\"That is an {'upgrade' if colorspace_precision_diff > 0 else 'downgrade'} of {colorspace_precision_diff * 100:.1f}%.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./params/colorspace_high_con.json\")\n",
    "\n",
    "df[\"precision\"] = df[\"precision\"].apply(lambda x: x[0])\n",
    "\n",
    "df[\"precision\"] = df[\"precision\"] - base_precision\n",
    "\n",
    "pivot_table = df.set_index(\"target_space\")\n",
    "\n",
    "pivot_table = pivot_table.sort_index().sort_index(axis=1).iloc[::-1]\n",
    "\n",
    "pivot_table_pct = pivot_table * 100\n",
    "\n",
    "vabs = max(abs(pivot_table_pct.min().min()), abs(pivot_table_pct.max().max()))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "\tpivot_table_pct,\n",
    "\tannot=True,\n",
    "\tfmt=\".1f\",\n",
    "\tcmap=\"RdYlGn\",\n",
    "\tcbar_kws={\"label\": alpha, \"format\": \"%.0f%%\"},\n",
    "\tvmin=-vabs,\n",
    "\tvmax=vabs,\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.yticks(rotation=0)\n",
    "\n",
    "plt.title(\"Correlation between Color Space Parameters and Model Precision\")\n",
    "plt.ylabel(\"Target Color Space\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_precisions = {\n",
    "\tNormalizeTransform.__name__: (normalize_precision, normalize_training_time),\n",
    "\tEqualizationTransform.__name__: (equalized_precision, equalized_training_time),\n",
    "\tDenoiseTransform.__name__: (denoise_precision, denoise_training_time),\n",
    "\tColorSpaceTransform.__name__: (colorspace_precision, colorspace_training_time),\n",
    "}\n",
    "\n",
    "class1_df_data = [\n",
    "\t{\n",
    "\t\t\"transform_1\": k.split(\", \")[0],\n",
    "\t\t\"precision\": v[0],\n",
    "\t\talpha: v[0] - base_precision,\n",
    "\t\t\"training_time\": v[1],\n",
    "\t\t\"training_time_ratio\": v[1] / base_training_time,\n",
    "\t}\n",
    "\tfor k, v in class1_precisions.items()\n",
    "]\n",
    "class1_df = pd.DataFrame(class1_df_data).sort_values(alpha, ascending=False).reset_index(drop=True)\n",
    "class1_df.transform_1 = class1_df.transform_1.apply(lambda x: preprocess_labels[x])\n",
    "class1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 2 Models: Images with two pre-processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_precisions = {}\n",
    "\n",
    "for idx, combination in enumerate(preprocess_combinations[2]):\n",
    "\t(\n",
    "\t\tclass2_train_loader,\n",
    "\t\tclass2_test_loader,\n",
    "\t\tclass2_validation_loader,\n",
    "\t) = get_model_data(\n",
    "\t\tcombination,\n",
    "\t\ttraining_ratio=training_ratio,\n",
    "\t\ttesting_ratio=testing_ratio,\n",
    "\t\tvalidation_ratio=validation_ratio,\n",
    "\t\tseed=seed,\n",
    "\t)\n",
    "\n",
    "\tcurr_precision, curr_confusion_matrix, curr_training_time = evaluate_model(\n",
    "\t\tdevice, class2_train_loader, class2_test_loader, class2_validation_loader, verbose=False,\n",
    "\t)\n",
    "\n",
    "\tuuid = \", \".join([str(t.__class__.__name__) for t in combination])\n",
    "\n",
    "\tclass2_precisions[uuid] = (curr_precision, curr_training_time)\n",
    "\n",
    "\tcurr_precision_diff = curr_precision - base_precision\n",
    "\n",
    "\tprint(f\"\\n\\nClass 2.{idx + 1} {uuid} precision: {curr_precision * 100:.1f}%\")\n",
    "\tprint(f\"That is an {'upgrade' if curr_precision_diff > 0 else 'downgrade'} of {curr_precision_diff * 100:.1f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2_df_data = [\n",
    "\t{\n",
    "\t\t\"transform_1\": k.split(\", \")[0],\n",
    "\t\t\"transform_2\": k.split(\", \")[1],\n",
    "\t\t\"precision\": v[0],\n",
    "\t\talpha: v[0] - base_precision,\n",
    "\t\t\"training_time\": v[1],\n",
    "\t\t\"training_time_ratio\": v[1] / base_training_time,\n",
    "\t}\n",
    "\tfor k, v in class2_precisions.items()\n",
    "]\n",
    "class2_df = pd.DataFrame(class2_df_data).sort_values(alpha, ascending=False).reset_index(drop=True)\n",
    "class2_df.transform_1 = class2_df.transform_1.apply(lambda x: preprocess_labels[x])\n",
    "class2_df.transform_2 = class2_df.transform_2.apply(lambda x: preprocess_labels[x])\n",
    "class2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = class2_df.groupby([\"transform_1\", \"transform_2\"]).mean()\n",
    "grouped[alpha] *= 100\n",
    "\n",
    "vabs = max(abs(grouped.min().min()), abs(grouped.max().max()))\n",
    "\n",
    "pivot = grouped[alpha].unstack()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "\tpivot, annot=True, fmt=\".1f\", cmap=\"RdYlGn\", cbar_kws={\"label\": alpha, \"format\": \"%.0f%%\"}, vmax=vabs, vmin=-vabs,\n",
    ")\n",
    "plt.title(\"Model Precision by Transform Combinations\")\n",
    "plt.ylabel(\"Transform 1\")\n",
    "plt.xlabel(\"Transform 2\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 3 Models: Images with three pre-processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class3_precisions = {}\n",
    "\n",
    "for idx, combination in enumerate(preprocess_combinations[3]):\n",
    "\t(\n",
    "\t\tclass3_train_loader,\n",
    "\t\tclass3_test_loader,\n",
    "\t\tclass3_validation_loader,\n",
    "\t) = get_model_data(\n",
    "\t\tcombination,\n",
    "\t\ttraining_ratio=training_ratio,\n",
    "\t\ttesting_ratio=testing_ratio,\n",
    "\t\tvalidation_ratio=validation_ratio,\n",
    "\t\tseed=seed,\n",
    "\t)\n",
    "\n",
    "\tcurr_precision, curr_confusion_matrix, curr_training_time = evaluate_model(\n",
    "\t\tdevice, class3_train_loader, class3_test_loader, class3_validation_loader, verbose=False,\n",
    "\t)\n",
    "\n",
    "\tuuid = \"→\".join([str(t.__class__.__name__) for t in combination])\n",
    "\n",
    "\tclass3_precisions[uuid] = (curr_precision, curr_training_time)\n",
    "\n",
    "\tcurr_precision_diff = curr_precision - base_precision\n",
    "\n",
    "\tprint(f\"\\n\\nClass 3.{idx + 1} {uuid} precision: {curr_precision * 100:.1f}%\")\n",
    "\tprint(f\"That is an {'upgrade' if curr_precision_diff > 0 else 'downgrade'} of {curr_precision_diff * 100:.1f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class3_df_data = [\n",
    "\t{\n",
    "\t\t\"transform_1\": k.split(\"→\")[0],\n",
    "\t\t\"transform_2\": k.split(\"→\")[1],\n",
    "\t\t\"transform_3\": k.split(\"→\")[2],\n",
    "\t\t\"precision\": v[0],\n",
    "\t\talpha: v[0] - base_precision,\n",
    "\t\t\"training_time\": v[1],\n",
    "\t\t\"training_time_ratio\": v[1] / base_training_time,\n",
    "\t}\n",
    "\tfor k, v in class3_precisions.items()\n",
    "]\n",
    "class3_df = pd.DataFrame(class3_df_data).sort_values(alpha, ascending=False).reset_index(drop=True)\n",
    "class3_df.transform_1 = class3_df.transform_1.apply(lambda x: preprocess_labels[x])\n",
    "class3_df.transform_2 = class3_df.transform_2.apply(lambda x: preprocess_labels[x])\n",
    "class3_df.transform_3 = class3_df.transform_3.apply(lambda x: preprocess_labels[x])\n",
    "class3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = preprocess_labels.values()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Heatmap for Transform 1 vs Alpha\n",
    "plt.subplot(1, 3, 1)\n",
    "# Calculate mean alpha for each category in transform_1\n",
    "pivot_t1 = class3_df.pivot_table(values=alpha, index=\"transform_1\", aggfunc=\"mean\").reindex(order)\n",
    "# Transpose for heatmap\n",
    "pivot_t1 = pivot_t1.T\n",
    "sns.heatmap(pivot_t1, annot=True, cmap=\"RdYlGn\", cbar=False)\n",
    "plt.title(\"Impact of Transform 1 on Alpha\")\n",
    "plt.xlabel(\"Transform 1\")\n",
    "plt.yticks([])  # Hide y-axis labels\n",
    "\n",
    "# Heatmap for Transform 2 vs Alpha\n",
    "plt.subplot(1, 3, 2)\n",
    "# Calculate mean alpha for each category in transform_2\n",
    "pivot_t2 = class3_df.pivot_table(values=alpha, index=\"transform_2\", aggfunc=\"mean\").reindex(order)\n",
    "# Transpose for heatmap\n",
    "pivot_t2 = pivot_t2.T\n",
    "sns.heatmap(pivot_t2, annot=True, cmap=\"RdYlGn\", cbar=False)\n",
    "plt.title(\"Impact of Transform 2 on Alpha\")\n",
    "plt.xlabel(\"Transform 2\")\n",
    "plt.yticks([])  # Hide y-axis labels\n",
    "\n",
    "# Heatmap for Transform 3 vs Alpha\n",
    "plt.subplot(1, 3, 3)\n",
    "# Calculate mean alpha for each category in transform_3\n",
    "pivot_t3 = class3_df.pivot_table(values=alpha, index=\"transform_3\", aggfunc=\"mean\").reindex(order)\n",
    "# Transpose for heatmap\n",
    "pivot_t3 = pivot_t3.T\n",
    "sns.heatmap(pivot_t3, annot=True, cmap=\"RdYlGn\", cbar=False)\n",
    "plt.title(\"Impact of Transform 3 on Alpha\")\n",
    "plt.xlabel(\"Transform 3\")\n",
    "plt.yticks([])  # Hide y-axis labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional Heatmaps for Combined Transforms\n",
    "\n",
    "# Heatmap for Transform 1 and Transform 2\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# pivot_t1_t2 = class3_df.pivot_table(values=alpha, index='transform_1', columns='transform_2', aggfunc='mean').reindex(index=order, columns=order)\n",
    "# sns.heatmap(pivot_t1_t2, annot=True, cmap='RdYlGn', linewidths=0.5, linecolor='gray')\n",
    "# plt.title('Impact of Transform 1 and Transform 2 on Alpha')\n",
    "# plt.xlabel('Transform 2')\n",
    "# plt.ylabel('Transform 1')\n",
    "# plt.show()\n",
    "\n",
    "# # Heatmap for Transform 1 and Transform 3\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# pivot_t1_t3 = class3_df.pivot_table(values=alpha, index='transform_1', columns='transform_3', aggfunc='mean').reindex(index=order, columns=order)\n",
    "# sns.heatmap(pivot_t1_t3, annot=True, cmap='RdYlGn', linewidths=0.5, linecolor='gray')\n",
    "# plt.title('Impact of Transform 1 and Transform 3 on Alpha')\n",
    "# plt.xlabel('Transform 3')\n",
    "# plt.ylabel('Transform 1')\n",
    "# plt.show()\n",
    "\n",
    "# # Heatmap for Transform 2 and Transform 3\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# pivot_t2_t3 = class3_df.pivot_table(values=alpha, index='transform_2', columns='transform_3', aggfunc='mean').reindex(index=order, columns=order)\n",
    "# sns.heatmap(pivot_t2_t3, annot=True, cmap='RdYlGn', linewidths=0.5, linecolor='gray')\n",
    "# plt.title('Impact of Transform 2 and Transform 3 on Alpha')\n",
    "# plt.xlabel('Transform 3')\n",
    "# plt.ylabel('Transform 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 4 Models: Images with four pre-processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class4_precisions = {}\n",
    "\n",
    "for idx, combination in enumerate(preprocess_combinations[4]):\n",
    "\t(\n",
    "\t\tclass4_train_loader,\n",
    "\t\tclass4_test_loader,\n",
    "\t\tclass4_validation_loader,\n",
    "\t) = get_model_data(\n",
    "\t\tcombination,\n",
    "\t\ttraining_ratio=training_ratio,\n",
    "\t\ttesting_ratio=testing_ratio,\n",
    "\t\tvalidation_ratio=validation_ratio,\n",
    "\t\tseed=seed,\n",
    "\t)\n",
    "\n",
    "\tcurr_precision, curr_confusion_matrix, curr_training_time = evaluate_model(\n",
    "\t\tdevice, class4_train_loader, class4_test_loader, class4_validation_loader, verbose=False,\n",
    "\t)\n",
    "\n",
    "\tuuid = \"➔\".join([str(t.__class__.__name__) for t in combination])\n",
    "\n",
    "\tclass4_precisions[uuid] = (curr_precision, curr_training_time)\n",
    "\n",
    "\tcurr_precision_diff = curr_precision - base_precision\n",
    "\n",
    "\tprint(f\"\\n\\nClass 4.{idx + 1} {uuid} precision: {curr_precision * 100:.1f}%\")\n",
    "\tprint(f\"That is an {'upgrade' if curr_precision_diff > 0 else 'downgrade'} of {curr_precision_diff * 100:.1f}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class4_df_data = [\n",
    "\t{\n",
    "\t\t\"transform_1\": k.split(\"➔\")[0],\n",
    "\t\t\"transform_2\": k.split(\"➔\")[1],\n",
    "\t\t\"transform_3\": k.split(\"➔\")[2],\n",
    "\t\t\"transform_4\": k.split(\"➔\")[3],\n",
    "\t\t\"precision\": v[0],\n",
    "\t\talpha: v[0] - base_precision,\n",
    "\t\t\"training_time\": v[1],\n",
    "\t\t\"training_time_ratio\": v[1] / base_training_time,\n",
    "\t}\n",
    "\tfor k, v in class4_precisions.items()\n",
    "]\n",
    "class4_df = pd.DataFrame(class4_df_data).sort_values(alpha, ascending=False).reset_index(drop=True)\n",
    "class4_df.transform_1 = class4_df.transform_1.apply(lambda x: preprocess_labels[x])\n",
    "class4_df.transform_2 = class4_df.transform_2.apply(lambda x: preprocess_labels[x])\n",
    "class4_df.transform_3 = class4_df.transform_3.apply(lambda x: preprocess_labels[x])\n",
    "class4_df.transform_4 = class4_df.transform_4.apply(lambda x: preprocess_labels[x])\n",
    "class4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_df = (\n",
    "\tpd.concat([class1_df, class2_df, class3_df, class4_df], axis=0)\n",
    "\t.reset_index(drop=True)\n",
    "\t.fillna(\"-\")[[\"transform_1\", \"transform_2\", \"transform_3\", \"transform_4\", alpha, \"training_time_ratio\"]]\n",
    ")\n",
    "analysis_df[alpha] *= 100\n",
    "analysis_df[f\"w{alpha}\"] = analysis_df[alpha] / analysis_df[\"training_time_ratio\"]\n",
    "analysis_df.head(100).sort_values(f\"w{alpha}\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"./dataset/diseased/ISIC_0024319.jpg\"\n",
    "N_COLS = 3\n",
    "\n",
    "base_pil = Image.open(IMAGE_PATH).convert(\"RGB\")\n",
    "base_tensor = TF.to_tensor(base_pil)\n",
    "\n",
    "images = [base_pil]\n",
    "captions = [\"Original\"]\n",
    "\n",
    "preprocess_map = {preprocess_labels[proc.__class__.__name__]: proc for proc in preprocesses}\n",
    "\n",
    "transform_columns = [\"transform_1\", \"transform_2\", \"transform_3\", \"transform_4\"]\n",
    "\n",
    "for _, row in analysis_df.sort_values(alpha, ascending=False).reset_index().iloc[:5][transform_columns].iterrows():\n",
    "\timg_t = base_tensor\n",
    "\tnames = row.to_list()\n",
    "\tperm = [preprocess_map[name] for name in names if name in preprocess_map and name != \"-\"]\n",
    "\n",
    "\tfor proc in perm:\n",
    "\t\timg_t = proc(img_t)\n",
    "\n",
    "\timages.append(TF.to_pil_image(img_t))\n",
    "\tif perm:\n",
    "\t\tlabels = [preprocess_labels[p.__class__.__name__] for p in perm]\n",
    "\t\tcaptions.append(\" → \".join(labels))\n",
    "\telse:\n",
    "\t\tcaptions.append(\"Original\")\n",
    "\n",
    "n_images = len(images)\n",
    "n_rows = math.ceil(n_images / N_COLS)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, N_COLS, figsize=(4 * N_COLS, 4 * n_rows))\n",
    "fig.patch.set_alpha(0)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, img, title in zip(axes, images, captions, strict=False):\n",
    "\tax.imshow(img)\n",
    "\tax.axis(\"off\")\n",
    "\tax.text(0.5, -0.1, title, size=20, ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "# turn off any extra axes\n",
    "for ax in axes[n_images:]:\n",
    "\tax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"top5.png\", transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dill.dump_session(datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \"_globalsave.pkl\")\n",
    "dill.load_session(\"checkpoints/2025-04-20_20-31-28_globalsave.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "undergrad_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
