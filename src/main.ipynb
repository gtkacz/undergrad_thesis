{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <p align=\"center\">\n",
    "        <img src=\"https://logodownload.org/wp-content/uploads/2017/09/mackenzie-logo-3.png\" style=\"height: 7ch;\"><br>\n",
    "        <h1 align=\"center\">Computer Systems Undergradute Thesis</h1>\n",
    "        <h2 align=\"center\">Quantitative Analysis of the Impact of Image Pre-Processing on the Accuracy of Computer Vision Models Trained to Identify Dermatological Skin Diseases</a>\n",
    "        <h4 align=\"center\">Gabriel Mitelman Tkacz</a>\n",
    "        </h4>\n",
    "    </p>\n",
    "</center>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tomllib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import clear_output\n",
    "from pynimbar import loading_animation\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from util import (\n",
    "    BinaryCNN,\n",
    "    EqualizationMethod,\n",
    "    LossFunction,\n",
    "    SkinDiseaseDataset,\n",
    "    TestingDataset,\n",
    "    TrainingDataset,\n",
    "    ValidationDataset,\n",
    "    split_datasets,\n",
    "    test_model,\n",
    "    train_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('parameters.toml', 'r') as f:\n",
    "    parameters = tomllib.loads(f.read())\n",
    "    \n",
    "loading_handler = partial(loading_animation, break_on_error=True, verbose_errors=True, time_it_live=True)\n",
    "\n",
    "pprint(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = parameters['TRAINING']['training_dataset_ratio']\n",
    "testing_ratio = validation_ratio = round(1 - training_ratio, 1) / 2\n",
    "\n",
    "print(f'Training ratio: {training_ratio*100}%')\n",
    "print(f'Testing ratio: {testing_ratio*100}%')\n",
    "print(f'Validation ratio: {validation_ratio*100}%')\n",
    "\n",
    "seed = 47\n",
    "print(f'\\nSeed: {seed}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_data(\n",
    "    transform: transforms.Compose = transforms.Compose(\n",
    "        [transforms.Resize((256, 256)), transforms.ToTensor()]\n",
    "    ),\n",
    ") -> tuple[TrainingDataset, DataLoader, TestingDataset, DataLoader, ValidationDataset, DataLoader]:\n",
    "    \"\"\"\n",
    "    This function returns the training and testing data loaders and datasets for the skin disease dataset.\n",
    "\n",
    "    Args:\n",
    "        transform (transforms.Compose, optional): The transformations to apply to the images. Defaults to transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()]).\n",
    "\n",
    "    Returns:\n",
    "        dict[str, dict[str, DataLoader | SkinDiseaseDataset]]: A dictionary containing the training and testing data loaders and datasets.\n",
    "    \"\"\"\n",
    "    loader_kwargs = {\n",
    "        \"batch_size\": parameters[\"TRAINING\"][\"batch_size\"],\n",
    "        \"shuffle\": parameters[\"TRAINING\"][\"shuffle\"],\n",
    "        \"num_workers\": parameters[\"TRAINING\"][\"num_workers\"],\n",
    "        \"pin_memory\": parameters[\"TRAINING\"][\"pin_memory\"],\n",
    "    }\n",
    "\n",
    "    base_dataset = SkinDiseaseDataset(root_dir=\"dataset\", transform=transform)\n",
    "    train_dataset, test_dataset, validation_dataset = split_datasets(\n",
    "        base_dataset, training_ratio, testing_ratio, validation_ratio, seed\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, **loader_kwargs)\n",
    "    test_loader = DataLoader(test_dataset, **loader_kwargs)\n",
    "    validation_loader = DataLoader(validation_dataset, **loader_kwargs)\n",
    "\n",
    "    return train_dataset, train_loader, test_dataset, test_loader, validation_dataset, validation_loader\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    device: torch.device,\n",
    "    train_loader: DataLoader,\n",
    "    test_loader: DataLoader,\n",
    "    criterion: LossFunction = nn.MSELoss(),\n",
    "    optimizer_class: type[optim.Optimizer] = optim.Adam,\n",
    "    learning_rate: float = parameters[\"TRAINING\"][\"learning_rate\"],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    This function evaluates the model using the given criterion and data loaders.\n",
    "\n",
    "    Args:\n",
    "        device (torch.device): The device to use for the evaluation.\n",
    "        train_loader (DataLoader): The training data loader.\n",
    "        test_loader (DataLoader): The testing data loader.\n",
    "        validation_loader (DataLoader): The validation data loader.\n",
    "        criterion (LossFunction): The loss function to use for the evaluation. Defaults to nn.BCELoss().\n",
    "        optimizer_class (type[optim.Optimizer], optional): The optimizer class to use for the evaluation. Defaults to optim.Adagrad.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model.\n",
    "    \"\"\"\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    model = BinaryCNN(device=device).to(device)\n",
    "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)  # type: ignore\n",
    "\n",
    "    # fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # fig.suptitle('Sample images from the training dataset')\n",
    "\n",
    "    # for i, (image, label) in enumerate(train_loader):\n",
    "    #     ax[i].imshow(image[0].permute(1, 2, 0))\n",
    "    #     ax[i].set_title(f'Label: {\"diseased\" if label[0] else \"healthy\"}')\n",
    "    #     ax[i].axis('off')\n",
    "\n",
    "    #     if i == 2:\n",
    "    #         break\n",
    "\n",
    "    # clear_output(wait=True)\n",
    "    # plt.show()\n",
    "\n",
    "    train_model(\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        verbose=False,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        data_loader=train_loader,\n",
    "    )\n",
    "\n",
    "    return test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 0 Model: Images with no pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_train_dataset, base_train_loader, base_test_dataset, base_test_loader, base_validation_dataset, base_validation_loader = get_model_data()\n",
    "\n",
    "with loading_handler(text='Evaluating the model on the base dataset...'):\n",
    "    base_precision = evaluate_model(device, base_train_loader, base_test_loader)\n",
    "\n",
    "print(f'Base precision: {base_precision*100:.2f}%')\n",
    "\n",
    "if base_precision < parameters['TRAINING']['precision_threshold']:\n",
    "    raise ValueError('The base model did not meet the precision threshold.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 1 Models: Images with only one pre-process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class 1.1 Models: Normalizing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, train_loader, test_dataset, test_loader = get_model_data(transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor(), transforms.Normalize(mean=[0.25, 0.25, 0.25], std=[0.25, 0.25, 0.25])]))\n",
    "\n",
    "with loading_handler(text='Evaluating the model on a normalized dataset...'):\n",
    "    precision = evaluate_model(device, train_loader, test_loader)\n",
    "\n",
    "normalize_precision = precision\n",
    "\n",
    "print(f'Precision: {precision*100:.2f}%')\n",
    "\n",
    "print(f'Improvement: {100*(precision - base_precision):.2f}%')\n",
    "\n",
    "if precision > base_precision:\n",
    "    print('The method is an improvement.')\n",
    "\n",
    "else:\n",
    "    print('The method is not an improvement.')\n",
    "\n",
    "print('-' * 20)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
